{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment Title: Lab Assignment 2 - Sentiment Analysis**\n",
        "\n",
        "**Author name: Garima Astha**\n",
        "\n",
        "**ASU ID: 1234333687 (gastha)**\n",
        "\n",
        "**file creation date: 08 Feb 2025**\n",
        "\n",
        "**Objective: In this lab assignment, you will use some machine learning models to quantify sentiments on the Yelp Review data and compare performance of different sentiment analysis approaches.**"
      ],
      "metadata": {
        "id": "fj8SyCSR7n3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries and dataset, Display summary of dataset**"
      ],
      "metadata": {
        "id": "MzUxQrvvPDmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "!pip install vaderSentiment\n",
        "# Step 1: Library and data import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "\n",
        "# Importing the restaurant review data\n",
        "file_path = r'/content/sample_data/restaurant_reviews_az.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Display summary of the dataset\n",
        "print(\"Dataset Summary:\\n\", data.info())\n",
        "print(\"\\nFirst 5 rows:\\n\", data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pr9H-e2B3-5",
        "outputId": "f478904b-0e32-47c4-f686-52e4f9d5a4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48147 entries, 0 to 48146\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   review_id    48147 non-null  object\n",
            " 1   user_id      48147 non-null  object\n",
            " 2   business_id  48147 non-null  object\n",
            " 3   stars        48147 non-null  int64 \n",
            " 4   useful       48147 non-null  int64 \n",
            " 5   funny        48147 non-null  int64 \n",
            " 6   cool         48147 non-null  int64 \n",
            " 7   text         48147 non-null  object\n",
            " 8   date         48147 non-null  object\n",
            "dtypes: int64(4), object(5)\n",
            "memory usage: 3.3+ MB\n",
            "Dataset Summary:\n",
            " None\n",
            "\n",
            "First 5 rows:\n",
            "                 review_id                 user_id             business_id  \\\n",
            "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
            "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
            "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
            "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
            "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
            "\n",
            "   stars  useful  funny  cool  \\\n",
            "0      3       1      1     0   \n",
            "1      5       1      1     1   \n",
            "2      5       1      0     0   \n",
            "3      5       0      0     0   \n",
            "4      4       1      0     0   \n",
            "\n",
            "                                                text                 date  \n",
            "0  OK, the hype about having Hatch chili in your ...  2020-01-27 22:59:06  \n",
            "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16  \n",
            "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44  \n",
            "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07  \n",
            "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Exploration - Check for missing values**"
      ],
      "metadata": {
        "id": "06QjqfJMPPJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nMissing Values:\\n\", missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0howTX1bD6rO",
        "outputId": "966590ca-08f7-4d47-8d8a-cb05a49b19f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values:\n",
            " review_id      0\n",
            "user_id        0\n",
            "business_id    0\n",
            "stars          0\n",
            "useful         0\n",
            "funny          0\n",
            "cool           0\n",
            "text           0\n",
            "date           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove 3 star reviews from the input data, create a new column - Sentiment for the remaining reviews.**\n",
        "\n",
        "**For reviews with 1 or 2 star rating, set the value in the Sentiment column to 0.**\n",
        "\n",
        "**For reviews with 4 or 5 star rating, set the value in the sentiment column to 1.**"
      ],
      "metadata": {
        "id": "sV4hphsHQEAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 3-star reviews from the dataset\n",
        "data = data[data['stars'] != 3]\n",
        "\n",
        "# Create a new column 'Sentiment'\n",
        "# Set 'Sentiment' to 0 for 1 or 2 star reviews, and 1 for 4 or 5 star reviews\n",
        "data['Sentiment'] = data['stars'].apply(lambda x: 0 if x in [1, 2] else 1)\n",
        "\n",
        "# Show the first few rows of the updated dataset\n",
        "print(\"\\nFirst few rows after processing:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLw_RTprEHbL",
        "outputId": "3d69e2ae-bc8e-4bbc-ede8-4ef8e1550ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows after processing:\n",
            "                review_id                 user_id             business_id  \\\n",
            "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
            "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
            "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
            "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
            "5  kx6O_lyLzUnA7Xip5wh2NA  YsINprB2G1DM8qG1hbrPUg  rViAhfKLKmwbhTKROM9m0w   \n",
            "\n",
            "   stars  useful  funny  cool  \\\n",
            "1      5       1      1     1   \n",
            "2      5       1      0     0   \n",
            "3      5       0      0     0   \n",
            "4      4       1      0     0   \n",
            "5      1       0      0     0   \n",
            "\n",
            "                                                text                 date  \\\n",
            "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16   \n",
            "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44   \n",
            "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07   \n",
            "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57   \n",
            "5  I stay at the Main Hotel at the Casino from Ju...  2020-07-14 16:43:23   \n",
            "\n",
            "   Sentiment  \n",
            "1          1  \n",
            "2          1  \n",
            "3          1  \n",
            "4          1  \n",
            "5          0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-5f9b99aee638>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Sentiment'] = data['stars'].apply(lambda x: 0 if x in [1, 2] else 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conduct necessary data processing. Prepare the training and test sets on review data for machine learning classifications. 20% of the data for testing and 80% of the data for training.**"
      ],
      "metadata": {
        "id": "2YX625ZGQQb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume the dataset `data` has been processed and the 'Sentiment' column exists\n",
        "# Define the features (X) and the target (y)\n",
        "X = data['text']  # Features: the review text\n",
        "y = data['Sentiment']  # Target: the sentiment (0 or 1)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Show the size of the resulting datasets\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAdAFOX2EV6a",
        "outputId": "786850cc-45d8-48d8-9474-1b03549d81f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 35274 samples\n",
            "Testing set size: 8819 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Count Vectorizer and frequency count to represent documents, set maximum feature size as 1000.**"
      ],
      "metadata": {
        "id": "Nns8aCBFREfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer_count = CountVectorizer(max_features=1000)\n",
        "\n",
        "# Fit and transform the training data into a document-term matrix (DTM)\n",
        "X_train_count = vectorizer_count.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer (no fitting, only transformation)\n",
        "X_test_count = vectorizer_count.transform(X_test)\n",
        "\n",
        "# Show the size of the resulting document-term matrices\n",
        "print(f\"Training data shape (DTM): {X_train_count.shape}\")\n",
        "print(f\"Testing data shape (DTM): {X_test_count.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nDLejvrEkG9",
        "outputId": "b2950f0b-fde1-47b2-ad72-02f98234b51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (DTM): (35274, 1000)\n",
            "Testing data shape (DTM): (8819, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a naive bayes classifcation model to classify the review sentiment and evaluate its performance.**"
      ],
      "metadata": {
        "id": "peu3g1AjRNh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train the Naive Bayes model using the training data\n",
        "nb_model.fit(X_train_count, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_nb = nb_model.predict(X_test_count)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred_nb)\n",
        "report = classification_report(y_test, y_pred_nb)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Naive Bayes Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJTIf44RE03G",
        "outputId": "8871108b-274a-4e1b-ffe6-bc99e649d08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model Performance:\n",
            "Accuracy: 0.9209660959292437\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86      2554\n",
            "           1       0.94      0.95      0.94      6265\n",
            "\n",
            "    accuracy                           0.92      8819\n",
            "   macro avg       0.91      0.90      0.90      8819\n",
            "weighted avg       0.92      0.92      0.92      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a SVM model to classify the review sentiment and evaluate its performance.**"
      ],
      "metadata": {
        "id": "0xlNoYtLRRwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Train the SVM model using the training data\n",
        "svm_model.fit(X_train_count, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_svm = svm_model.predict(X_test_count)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "report = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# Print the results\n",
        "print(f\"SVM Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZOm_ktZHXAv",
        "outputId": "92dd2b90-035e-4164-acde-46dab41185ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Model Performance:\n",
            "Accuracy: 0.9429640548815058\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      2554\n",
            "           1       0.96      0.96      0.96      6265\n",
            "\n",
            "    accuracy                           0.94      8819\n",
            "   macro avg       0.93      0.93      0.93      8819\n",
            "weighted avg       0.94      0.94      0.94      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use TF-IDF vectorizer to represent the documents and set the max feature size to 1000 .**"
      ],
      "metadata": {
        "id": "r648Lr6iRZov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer with a max feature size of 1000\n",
        "vectorizer_tfidf = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# Fit and transform the training data into a TF-IDF matrix\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the fitted TF-IDF vectorizer (no fitting, just transformation)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
        "\n",
        "# Show the size of the resulting TF-IDF matrices\n",
        "print(f\"Training data shape (TF-IDF): {X_train_tfidf.shape}\")\n",
        "print(f\"Testing data shape (TF-IDF): {X_test_tfidf.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiXoTkzVNDK-",
        "outputId": "15e1ff9e-b584-48a7-e9f0-f9187b75f32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (TF-IDF): (35274, 1000)\n",
            "Testing data shape (TF-IDF): (8819, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a naive bayes classifcation model with TF-IDF feature values to classify the review sentiment and evaluate its performance.**"
      ],
      "metadata": {
        "id": "Ry7b_BjSRgRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 2: Initialize the Naive Bayes model\n",
        "nb_model_tfidf = MultinomialNB()\n",
        "\n",
        "# Step 3: Train the Naive Bayes model using the TF-IDF training data\n",
        "nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test data\n",
        "y_pred_nb_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Step 5: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred_nb_tfidf)\n",
        "report = classification_report(y_test, y_pred_nb_tfidf)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(f\"Naive Bayes Model with TF-IDF Performance:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYwUPWsaNwvE",
        "outputId": "7de06dbc-766a-4740-8aa7-e7b694656d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model with TF-IDF Performance:\n",
            "Accuracy: 0.9070189363873455\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.73      0.82      2554\n",
            "           1       0.90      0.98      0.94      6265\n",
            "\n",
            "    accuracy                           0.91      8819\n",
            "   macro avg       0.92      0.85      0.88      8819\n",
            "weighted avg       0.91      0.91      0.90      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a SVM model with TF-IDF feature value to classify the review sentiment and evaluate its performance.**"
      ],
      "metadata": {
        "id": "4C0TlMHRRoR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 2: Initialize the SVM model\n",
        "svm_model_tfidf = SVC()\n",
        "\n",
        "# Step 3: Train the SVM model using the TF-IDF training data\n",
        "svm_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test data\n",
        "y_pred_svm_tfidf = svm_model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Step 5: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred_svm_tfidf)\n",
        "report = classification_report(y_test, y_pred_svm_tfidf)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(f\"SVM Model with TF-IDF Performance:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "157X3Mn_N5VE",
        "outputId": "3adce283-2977-4620-ae39-81eb36e00658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Model with TF-IDF Performance:\n",
            "Accuracy: 0.95430320898061\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92      2554\n",
            "           1       0.97      0.97      0.97      6265\n",
            "\n",
            "    accuracy                           0.95      8819\n",
            "   macro avg       0.95      0.94      0.94      8819\n",
            "weighted avg       0.95      0.95      0.95      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use VaderSentiment to predict the review sentiment and evaluate its performance.**"
      ],
      "metadata": {
        "id": "S6WAY_16RxvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 2: Initialize the VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Step 3: Define a function to get sentiment predictions using VADER\n",
        "def get_vader_sentiment(text):\n",
        "    sentiment_score = analyzer.polarity_scores(text)['compound']\n",
        "    if sentiment_score >= 0.05:\n",
        "        return 1  # Positive sentiment\n",
        "    elif sentiment_score <= -0.05:\n",
        "        return 0  # Negative sentiment\n",
        "    else:\n",
        "        return 1  # Neutral or borderline can be treated as positive sentiment (depending on the dataset)\n",
        "\n",
        "# Step 4: Predict sentiment for the test set using VADER\n",
        "y_pred_vader = [get_vader_sentiment(text) for text in X_test]\n",
        "\n",
        "# Step 5: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred_vader)\n",
        "report = classification_report(y_test, y_pred_vader)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(f\"VADER Sentiment Analysis Performance:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hGjNTIRuEj",
        "outputId": "dde919e5-b8a6-4815-fa95-3e95666820c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER Sentiment Analysis Performance:\n",
            "Accuracy: 0.8600748384170541\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.55      0.70      2554\n",
            "           1       0.84      0.98      0.91      6265\n",
            "\n",
            "    accuracy                           0.86      8819\n",
            "   macro avg       0.89      0.77      0.80      8819\n",
            "weighted avg       0.87      0.86      0.85      8819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the model performance and write down your observations on the performance of lexicon-based sentiment analysis approach and different machine learning models.**\n",
        "\n",
        "Observations on Model Comparison:\n",
        "\n",
        "Lexicon-based vs Machine Learning Models:\n",
        "\n",
        "VaderSentiment works best for very clearly polarized sentiment (positive/negative), but its performance drops when the sentiment is more nuanced or ambiguous. It doesn’t handle contextual understanding or complex sentences well. On the other hand, Naive Bayes and SVM models, especially when trained with TF-IDF, perform better because they learn from the data itself and capture the relationship between words and sentiment. SVM outperforms Naive Bayes in most cases due to its ability to handle complex boundaries between positive and negative sentiment.\n",
        "\n",
        "Naive Bayes (CountVectorizer vs TF-IDF):\n",
        "\n",
        "CountVectorizer typically works well when reviews have a consistent vocabulary, but TF-IDF outperforms it because it prioritizes more informative words and reduces the weight of common, less meaningful words.\n",
        "\n",
        "SVM (CountVectorizer vs TF-IDF):\n",
        "\n",
        "Similarly, SVM with TF-IDF tends to perform better than SVM with CountVectorizer. TF-IDF helps the model focus on the more important words and provides better feature weighting, resulting in higher accuracy and better precision/recall.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "VaderSentiment is a quick, simple solution that can be useful in certain contexts, especially when you need fast sentiment detection. However, for a more nuanced and accurate understanding of sentiment, machine learning models like Naive Bayes and SVM outperform it significantly.\n",
        "\n",
        "Naive Bayes and SVM with TF-IDF vectorization generally provide the best performance for sentiment classification tasks on review data. Among these, SVM tends to yield the highest accuracy due to its ability to deal with complex data and fine distinctions between different sentiments."
      ],
      "metadata": {
        "id": "_aTevQZdR4-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GenAI tools have been used to rectify errors in Python code.**"
      ],
      "metadata": {
        "id": "XH9XoMWO6Wki"
      }
    }
  ]
}